# Indexer Package Overview

**Indexer** captures the whole lifecycle of turning raw SAP ECC exports into a production-ready vector store. The package bundles two complementary CLIs‚Äî`prepare_datasets.py` and `vectorize.py`‚Äîplus shared libraries that handle schema management, data validation, partition manifests, resume metadata, and drop/remediation flows.

## Lifecycle in Three Acts

1. **Prepare** ‚Äì `prepare_datasets.py` stubs configs, sanitises CSVs, deduplicates rows, and writes manifest-tracked partitions. It detects schema changes, versions them, and marks older partitions stale.
2. **Index** ‚Äì `vectorize.py` streams validated partitions into Chroma (local or cloud), manages resume state, enforces batch token limits, and keeps partition-level persistence for incremental replays.
3. **Remediate** ‚Äì Both tools support drop planning and application so you can retire stale data, purge partitions, or re-ingest after schema shifts without losing traceability.

## Feature Highlights

- üîÑ **Schema-aware manifest** with versioning, stale partition tracking, and per-model metadata.
- üß† **Resume-friendly ingestion** (per model and per partition) that records file offsets and row indices.
- ü©π **CSV repair safeguards**; `prepare_datasets.py` stitches newline-fractured rows around a configured malformed column before deciding to drop them.
- ‚ö° **Digest caches** keep reruns fast by persisting per-partition row hashes alongside the CSVs.
- üß© **Pluggable model registries**; pass `--model <module:REGISTRY>` to target ECC defaults or your own knowledge domain.
- ‚òÅÔ∏è **Chroma transport flexibility**; switch between persistent client and HTTP/Cloud with a couple of flags.
- üßπ **Drop + remediation tooling** that mirrors the migration workflow and keeps audit history.

## Quick Start

```bash
# 1) Describe your registry target once
export MODEL_REGISTRY_TARGET="kb.std.ecc_6_0_ehp_7.registry:MODEL_REGISTRY"

# 2) Scaffold a dataset config
prepare_datasets.py new-config ecc-foundation --model "$MODEL_REGISTRY_TARGET"

# 3) Produce partitions (idempotent; MVCC-friendly)
prepare_datasets.py \
  --model "$MODEL_REGISTRY_TARGET" \
  --config configs/ecc_foundation.json \
  --output-root build/partitions

# 4) Index into Chroma and resume safely across runs
vectorize.py index \
  --model "$MODEL_REGISTRY_TARGET" \
  --partition-manifest build/partitions/manifest.json \
  --partition-out-dir build/vector \
  --collection ecc-std \
  --resume
```

Looking for deeper dives? Check out [`DOC.md`](DOC.md) for a narrative walkthrough and [`FAQ.md`](FAQ.md) for operational tips.
